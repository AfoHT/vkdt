#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable

#include "shared.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 1) uniform params_t
{
  float strength;
  float chroma;
  float luma;
  float envl;
  vec4  edge[9];
  vec4  blur[9];
  vec4  blck;
} params;

layout(push_constant, std140) uniform push_t
{
  vec4 wb;
  vec4 black;
  vec4 white;
  ivec4 crop;
  uint filters;
  float noise_a;
  float noise_b;
} push;

layout( // input uint16 buffer rggb
    set = 1, binding = 0
) uniform sampler2D img_in;

layout( // input f16 buffer rgb
    set = 1, binding = 1
) uniform sampler2D img_coarse;

layout( // output f16 buffer rggb
    set = 1, binding = 2
) uniform writeonly image2D img_out;

// upsample back to mosaic. this is either 3x3 or 2x2, depending on filters.
// runs on coarse resolution.
// our goal is to do one scale of decimated wavelet denoising, while keeping
// clipped pixels clipped (these will be copied straight to the output)
void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  vec4 upsm = texelFetch(img_coarse, ipos, 0);

  if(push.filters == 9)
  {
    // get original input texels
    float c0 = texelFetch(img_in, push.crop.xy + 3*ipos, 0).r;
    float c1 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(0,1), 0).r;
    float c2 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(0,2), 0).r;
    float c3 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(1,0), 0).r;
    float c4 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(1,1), 0).r;
    float c5 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(1,2), 0).r;
    float c6 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(2,0), 0).r;
    float c7 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(2,1), 0).r;
    float c8 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(2,2), 0).r;

    vec3 crs = vec3(
        (c1+c7)/2.0,
        (c0+c2+c4+c6+c8)/5.0,
        (c3+c5)/2.0);

    // swap red and blue channels according to sensor layout
    if(((ipos.x + ipos.y + push.crop.x + push.crop.y) & 1) == 0)
    {
      upsm.rgb = upsm.bgr;
      crs.rgb = crs.bgr;
    }
    // crs.rgb = upsm.rgb;

    // do wavelet shrinkage with these channels.
    // make sure to keep clipped (>= white)!
    // TODO: use black and white according to correct channel!
      // float D = (B - push.black.x)/(push.white.x - push.black.x);
#define SHRINK(A, B, C) {\
      A = (A - push.black.x)/(push.white.x - push.black.x);\
      float D = C;\
      if(A < 1.0) {\
        float wav = (A - D)/sigma;\
        float tt = min(1.0, wav/(2.0*T));\
        A = max(0, C + sigma * sign(wav) * mix(max(0.0, abs(wav) - T), abs(wav), tt));\
      }\
    }
 // max(0, (crs.g - push.black.g)/(push.white.g - push.black.g));
#define SHRINKG(A) {\
      A = max(0, (A - push.black.g)/(push.white.g - push.black.g));\
      float D = upsm.g;\
      if(A < 1.0) { \
        float wav = (A - D)/sigma;\
        float tt = min(1.0, wav/(2.0*T));\
        A = mix(A, max(0, upsm.g + sigma * sign(wav) * mix(max(0.0, abs(wav) - T), abs(wav), tt)), params.luma);\
      }\
    }

    // TODO: need explicit routing of raw -> assemble?

    const float scale = 65535.0*(push.white.g-push.black.g);
    const float sigma = sqrt(push.noise_a + scale*max(upsm.g, 0.0)*push.noise_b)/scale;
    float T = params.chroma * params.strength * upsm.w;
    SHRINK(c1, crs.r, upsm.r)
    SHRINK(c7, crs.r, upsm.r)
    SHRINK(c3, crs.b, upsm.b)
    SHRINK(c5, crs.b, upsm.b)

    T = params.strength * upsm.w;
    SHRINKG(c0)
    SHRINKG(c2)
    SHRINKG(c4)
    SHRINKG(c6)
    SHRINKG(c8)

    // c0 = c1 = c2 = c3 = c4 = c5 = c6 = c7 = c8 = upsm.w;

    imageStore(img_out, 3*ipos,            vec4(vec3(c0), 1));
    imageStore(img_out, 3*ipos+ivec2(0,1), vec4(vec3(c1), 1));
    imageStore(img_out, 3*ipos+ivec2(0,2), vec4(vec3(c2), 1));
    imageStore(img_out, 3*ipos+ivec2(1,0), vec4(vec3(c3), 1));
    imageStore(img_out, 3*ipos+ivec2(1,1), vec4(vec3(c4), 1));
    imageStore(img_out, 3*ipos+ivec2(1,2), vec4(vec3(c5), 1));
    imageStore(img_out, 3*ipos+ivec2(2,0), vec4(vec3(c6), 1));
    imageStore(img_out, 3*ipos+ivec2(2,1), vec4(vec3(c7), 1));
    imageStore(img_out, 3*ipos+ivec2(2,2), vec4(vec3(c8), 1));
  }
  else
  {
    // reads : w z -> r g
    //         x y    g b
    vec4 c = textureGather(img_in, (push.crop.xy + 2*(ipos+.5))/vec2(textureSize(img_in, 0)), 0);
    vec3 crs = vec3(upsm.r, 0.5*(c.z+c.x), upsm.b);

    const float sigma = sqrt(push.noise_a + 65535.0*max(upsm.g, 0.0)*push.noise_b)/65535.0;
    float T = params.chroma * params.strength * upsm.w;
    SHRINK(c.y, crs.b, upsm.b);
    SHRINK(c.w, crs.r, upsm.r);

    T = params.strength * upsm.w;
    SHRINKG(c.x);
    SHRINKG(c.z);
#undef SHRINK
#undef SHRINKG

    imageStore(img_out, 2*ipos,            vec4(c.w));
    imageStore(img_out, 2*ipos+ivec2(1,0), vec4(c.z));
    imageStore(img_out, 2*ipos+ivec2(0,1), vec4(c.x));
    imageStore(img_out, 2*ipos+ivec2(1,1), vec4(c.y));
  }
}
