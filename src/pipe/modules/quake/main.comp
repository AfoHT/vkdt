#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable
#extension GL_EXT_ray_tracing             : enable
#extension GL_EXT_ray_query               : enable

#include "shared.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 0) uniform global_t
{ 
  int frame;
} global;

layout(std140, set = 0, binding = 1) uniform params_t
{ 
  vec4 cam_x;
  vec4 cam_w;
  int spp;
} params;

layout(push_constant, std140) uniform push_t
{
  uint first_skybox;
} push;

layout(set = 1, binding = 0) uniform writeonly image2D img_irradiance;

// TODO: make this an array (and support more instances for decals etc)
layout(std430, set = 1, binding = 1) buffer sssbo_t
{
  uint v[]; // extra geo info for static geo
} stcssbo;

layout(std430, set = 1, binding = 2) buffer dssbo_t
{
  uint v[]; // extra geo info for dynamic geo
} dynssbo;

layout(set = 1, binding = 3) uniform sampler2D img_tex[];
layout(set = 1, binding = 4) uniform sampler2D img_blue;

layout(set = 1, binding = 5) uniform writeonly image2D img_albedo;

layout(set = 1, binding = 6) uniform usampler2D img_nee_in;
layout(set = 1, binding = 7) uniform writeonly uimage2D img_nee_out;
layout(set = 1, binding = 8) uniform sampler2D img_mv;

layout(set = 2, binding = 0) uniform accelerationStructureEXT rt_accel;

layout(set = 2, binding = 1) buffer buf_vtx_t
{ // 3x float vertex data for every instance
  float v[];
} buf_vtx[];

layout(set = 2, binding = 2) buffer buf_idx_t
{ // index data for every instance
  uint i[];
} buf_idx[];


#define M_PI   3.14159265358979323846
// importance sample the blackman harris pixel filter.
// has 1.5px radius support
vec2 filter_bh_sample(vec2 rand)
{
  vec2 res = vec2(cos(rand.y*M_PI*2.0), sin(rand.y*M_PI*2.0));
  float r = 0.943404 * asin(0.636617 * asin(sqrt(rand.x))); // surprisingly good fit to inverse cdf
  return res * r;
}


#if 0
float rand3(vec3 v) {
    return fract(sin(dot(v + vec3(-8.5123, 23.2156, 0.0), vec3(12.9898, 6.233, 0.84261))) * 47583.5453123);
}
float noise3lin(in vec3 uvx) {
    vec3 f = fract(uvx);
    vec3 i = floor(uvx);

    float a1 = rand3(i);
    float b1 = rand3(i + vec3(0.0, 1.0, 0.0));
    float c1 = rand3(i + vec3(1.0, 0.0, 0.0));
    float d1 = rand3(i + vec3(1.0, 1.0, 0.0));
    float a2 = rand3(i + vec3(0.0, 0.0, 1.0));
    float b2 = rand3(i + vec3(0.0, 1.0, 1.0));
    float c2 = rand3(i + vec3(1.0, 0.0, 1.0));
    float d2 = rand3(i + vec3(1.0, 1.0, 1.0));

    vec3 u = -2. * f * f * f + 3. * f * f;

    float a = mix(a1, a2, f.z);
    float b = mix(b1, b2, f.z);
    float c = mix(c1, c2, f.z);
    float d = mix(d1, d2, f.z);

    return mix(mix(a, b, u.y), mix(c, d, u.y), u.x);
}
float fbm3(in vec3 uvx) {
    float sum = 0.0;
    float amp = 0.0;
    float persistence = 0.7;
    vec3 stz = uvx;

    for (int i = 0; i < 8; ++i) {
        amp = amp / persistence + noise3lin(stz);
        sum = sum / persistence + 1.;
        stz *= 2.;
    }
    return amp / sum;
}
#endif


vec3 envmap(in vec3 w)
{
  // vec3 sundir = normalize(vec3(1, 1, 1)); // this where the moon is in ad_azad
  vec3 sundir = normalize(vec3(1, -1, 1)); // this comes in more nicely through the windows for debugging
  const float k0 = 4.0, k1 = 30.0, k2 = 4.0;
  vec3 emcol;
  emcol  = vec3(0.50, 0.50, 0.50) * /*(k0+1.0)/(2.0*M_PI)*/ pow(0.5*(1.0+dot(sundir, w)), k0);
  emcol += vec3(1.00, 0.70, 0.30) * /*(k1+1.0)/(2.0*M_PI)*/ pow(0.5*(1.0+dot(sundir, w)), k1);
  emcol += vec3(0.20, 0.08, 0.02) * /*(k2+1.0)/(2.0*M_PI)*/ pow(0.5*(1.0-w.z), k2);
  // emcol *= 2.0;
  // multiply with some background texture, if we have.
  // these are e.g. gfx/env/*{rt,bk,lf,ft,up,dn}
  int m = 0;
  if(abs(w.y) > abs(w.x) && abs(w.y) > abs(w.z)) m = 1;
  if(abs(w.z) > abs(w.x) && abs(w.z) > abs(w.y)) m = 2;
  uint side = 0;
  vec2 st;
  if     (m == 0 && w.x > 0) { side = 0; st = 0.5 + 0.5*vec2(-w.y, -w.z) / abs(w.x);} // rt
  else if(m == 0 && w.x < 0) { side = 2; st = 0.5 + 0.5*vec2( w.y, -w.z) / abs(w.x);} // lf
  else if(m == 1 && w.y > 0) { side = 1; st = 0.5 + 0.5*vec2( w.x, -w.z) / abs(w.y);} // bk
  else if(m == 1 && w.y < 0) { side = 3; st = 0.5 + 0.5*vec2(-w.x, -w.z) / abs(w.y);} // ft
  else if(m == 2 && w.z > 0) { side = 4; st = 0.5 + 0.5*vec2(-w.y,  w.x) / abs(w.z);} // up
  else if(m == 2 && w.z < 0) { side = 5; st = 0.5 + 0.5*vec2(-w.y, -w.x) / abs(w.z);} // dn
  side += push.first_skybox;
  ivec2 tc = 
      clamp(ivec2(textureSize(img_tex[nonuniformEXT(side)], 0)*st),
        ivec2(0), textureSize(img_tex[nonuniformEXT(side)], 0)-1);
  vec3 tex = texelFetch(img_tex[nonuniformEXT(side)], tc, 0).rgb;
  emcol += tex*tex; // mul "un-gamma"d sky texture
  return emcol;
}

#if 1 // TODO: put stuff like this in montecarlo.glsl or so

// sample hemisphere, cos lobe, p = cos(theta)/pi
vec3 sample_cos(vec2 x)
{
  float su = sqrt(x.x);
  return vec3(su*cos(2.0*3.1415*x.y), su*sin(2.0*3.1415*x.y), sqrt(1.0 - x.x));
}

float mrand(inout uint seed)
{ // Algorithm "xor" from p. 4 of Marsaglia, "Xorshift RNGs"
  seed ^= seed << 13;
  seed ^= seed >> 17;
  seed ^= seed << 5;
  return seed / 4294967296.0;
}

vec4 xrand(inout uint seed, ivec2 p)
{
  // cp shift based on seed
  return mod(texelFetch(img_blue, p, 0) + vec4(mrand(seed), mrand(seed), mrand(seed), mrand(seed)), vec4(1.0));
}

#endif

// 32-bit normal encoding from Journal of Computer Graphics Techniques Vol. 3, No. 2, 2014
// A Survey of Efficient Representations for Independent Unit Vectors,
// almost like oct30
vec3 geo_decode_normal(const uint enc)
{
  vec2 projected = unpackSnorm2x16(enc); // -1..1
  vec3 vec = vec3(projected, 1.0-abs(projected.x)-abs(projected.y));
  if(vec.z < 0.0)
    vec.xy = vec2(
        (1.0 - abs(vec.y)) * (vec.x < 0.0 ? -1.0 : 1.0),
        (1.0 - abs(vec.x)) * (vec.y < 0.0 ? -1.0 : 1.0));
  return normalize(vec);
}

struct intersection_t
{ // minimal descriptor to id a material_info_t
  int  instid;
  int  primid;
  uint uv;     // unpackHalf2x16
};

struct material_info_t
{ // initialised hit point to work with
  vec3 x;
  vec3 n, du, dv; // shading frame
  vec2 st;        // texture coordinates
  uint mat;       // albedo texture
  uint matfb;     // "fullbright" texture/emission
  vec3 albedo;
  vec3 emission;
};

intersection_t
prepare_intersection(
    rayQueryEXT rq)
{
  intersection_t inter;
  inter.instid = rayQueryGetIntersectionInstanceIdEXT(rq, true);     // which of our ssbo
  inter.primid = rayQueryGetIntersectionPrimitiveIndexEXT(rq, true); // primitive inside instance
  inter.uv     = packHalf2x16(rayQueryGetIntersectionBarycentricsEXT(rq, true));
  return inter;
}

material_info_t
prepare_material_info(
    vec3           x,      // incoming ray origin. only used if w.x == 666
    vec3           w,      // incoming ray direction. if w.x == 666, create by using new x and old x.
    intersection_t inter)  // identify geo intersection
{
  material_info_t m;
  vec3 b;
  b.yz = unpackHalf2x16(inter.uv);
  b.x = 1.0-b.z-b.y;
  int i = 7*inter.primid;
  vec3 n0, n1, n2;
  if(inter.instid == 0)
  { // dyn geo
    m.mat   = dynssbo.v[i+6]&0xffff;
    m.matfb = dynssbo.v[i+6]>>16;
    n0 = geo_decode_normal(dynssbo.v[i+0]);
    n1 = geo_decode_normal(dynssbo.v[i+1]);
    n2 = geo_decode_normal(dynssbo.v[i+2]);
    vec2 st0 = unpackHalf2x16(dynssbo.v[i+3]);
    vec2 st1 = unpackHalf2x16(dynssbo.v[i+4]);
    vec2 st2 = unpackHalf2x16(dynssbo.v[i+5]);
    m.st = mat3x2(st0, st1, st2) * b;
  }
  else
  { // static geo
    m.mat   = stcssbo.v[i+6]&0xffff;
    m.matfb = stcssbo.v[i+6]>>16;
    n0 = geo_decode_normal(stcssbo.v[i+0]);
    n1 = geo_decode_normal(stcssbo.v[i+1]);
    n2 = geo_decode_normal(stcssbo.v[i+2]);
    m.n = normalize(mat3(n0, n1, n2) * b);
    vec2 st0 = unpackHalf2x16(stcssbo.v[i+3]);
    vec2 st1 = unpackHalf2x16(stcssbo.v[i+4]);
    vec2 st2 = unpackHalf2x16(stcssbo.v[i+5]);
    m.st = mat3x2(st0, st1, st2) * b;
  }
  // more precise intersection point by using vertices + barycentrics
  uint i0 = buf_idx[inter.instid].i[3*inter.primid+0];
  uint i1 = buf_idx[inter.instid].i[3*inter.primid+1];
  uint i2 = buf_idx[inter.instid].i[3*inter.primid+2];
  vec3 v0 = vec3(
      buf_vtx[inter.instid].v[3*i0+0],
      buf_vtx[inter.instid].v[3*i0+1],
      buf_vtx[inter.instid].v[3*i0+2]);
  vec3 v1 = vec3(
      buf_vtx[inter.instid].v[3*i1+0],
      buf_vtx[inter.instid].v[3*i1+1],
      buf_vtx[inter.instid].v[3*i1+2]);
  vec3 v2 = vec3(
      buf_vtx[inter.instid].v[3*i2+0],
      buf_vtx[inter.instid].v[3*i2+1],
      buf_vtx[inter.instid].v[3*i2+2]);
  m.x = mat3(v0, v1, v2) * b;
  if(w.x == 666) w = normalize(m.x - x); // regenerate if no direction known
  if(inter.instid == 0)
  { // now fix shading normals below horizon and terminator problem:
    if(dot(w,n0) > 0) n0 -= w*dot(w,n0);
    if(dot(w,n1) > 0) n1 -= w*dot(w,n1);
    if(dot(w,n2) > 0) n2 -= w*dot(w,n2);
    m.n = normalize(mat3(n0, n1, n2) * b);
    vec3 tmpu = m.x - v0, tmpv = m.x - v1, tmpw = m.x - v2;
    float dotu = min(0.0, dot(tmpu, n0));
    float dotv = min(0.0, dot(tmpv, n1));
    float dotw = min(0.0, dot(tmpw, n2));
    tmpu -= dotu*n0;
    tmpv -= dotv*n1;
    tmpw -= dotw*n2;
    m.x += mat3(tmpu, tmpv, tmpw) * b;
  }

  // init tangent frame
  if(dot(w, m.n) > 0) m.n = -m.n; // never happens except when it does (transparent surfaces/sky)
  vec3 up = vec3(1,0,0);
  if(abs(m.n.x) > abs(m.n.y)) up = vec3(0,1,0);
  m.du = normalize(cross(up, m.n));
  m.dv = normalize(cross(m.du, m.n));
  m.albedo   = vec3(0);
  m.emission = vec3(0);
  if(m.mat == 0xffff)
  { // marked as sky
    m.albedo = vec3(0.0);
    m.emission = envmap(w);
  }
  else
  {
    ivec2 tc = ivec2(textureSize(img_tex[nonuniformEXT(m.mat)], 0)*mod(m.st, vec2(1.0)));
    tc = clamp(tc, ivec2(0), textureSize(img_tex[nonuniformEXT(m.mat)], 0)-1);
    m.albedo = texelFetch(img_tex[nonuniformEXT(m.mat)], tc, 0).rgb;
    m.albedo *= m.albedo; // "un-gamma"
    m.emission = m.matfb > 0 ? texelFetch(img_tex[nonuniformEXT(m.matfb)], tc, 0).rgb : vec3(0.0);
  }

  return m;
}

vec3 colourtex(vec2 st)
{
  if((fract(st.x * 200) < 0.5) ^^ (fract(st.y * 200) < 0.5))
    return vec3(0.3);
  return vec3(0.4);
}

vec3 nee_torch(
    in const vec3 lpos,
    in const vec3 x,
    in const vec3 rgb, // TODO: replace by some material that we can evaluate for directions
    in const vec3 n,
    inout uint seed,
    in ivec2 rp)
{
  rayQueryEXT rq;
  vec3 ws;
  float ldist = distance(lpos, x);
  float ao = 0.0;
  const int samples = 1;
  // for(int i=0;i<samples;i++)
  {
    vec4 rand = xrand(seed, rp);
    ws = normalize(lpos + 2.0*rand.xyz - x);
#if 1
    rayQueryInitializeEXT(rq, rt_accel,
        gl_RayFlagsNoneEXT,
        // gl_RayFlagsTerminateOnFirstHitEXT | gl_RayFlagsOpaqueEXT | gl_RayFlagsSkipClosestHitShaderEXT,
        0xFF, x, 1e-2, ws, ldist-1e-2);
    while(rayQueryProceedEXT(rq))
    {
      if (rayQueryGetIntersectionTypeEXT(rq, false) == gl_RayQueryCandidateIntersectionTriangleEXT)
      {
        int instance_id = rayQueryGetIntersectionInstanceIdEXT(rq, false); // which of our ssbo
        int pi = rayQueryGetIntersectionPrimitiveIndexEXT(rq, false); // primitive inside instance
        vec3 b;
        b.yz = rayQueryGetIntersectionBarycentricsEXT(rq, false);
        b.x = 1.0-b.z-b.y;
        // if(min(b.x,min(b.y,b.z)) < 0.05) rayQueryConfirmIntersectionEXT(rq); // wireframe
        int i = 7*pi;
        uint mat = 0;
        vec2 st;
        if(instance_id == 0)
        {
          mat   = dynssbo.v[i+6]&0xffff;
          vec2 st0 = unpackHalf2x16(dynssbo.v[i+3]);
          vec2 st1 = unpackHalf2x16(dynssbo.v[i+4]);
          vec2 st2 = unpackHalf2x16(dynssbo.v[i+5]);
          st = mat3x2(st0, st1, st2) * b;
        }
        else
        {
          mat   = stcssbo.v[i+6]&0xffff;
          vec2 st0 = unpackHalf2x16(stcssbo.v[i+3]);
          vec2 st1 = unpackHalf2x16(stcssbo.v[i+4]);
          vec2 st2 = unpackHalf2x16(stcssbo.v[i+5]);
          st = mat3x2(st0, st1, st2) * b;
        }
        if(mat == 0xffff) 
        { // sky, nothing behind it, right?
          rayQueryConfirmIntersectionEXT(rq);
        }
        else
        {
          ivec2 tc = ivec2(textureSize(img_tex[nonuniformEXT(mat)], 0)*mod(st, vec2(1.0)));
          tc = clamp(tc, ivec2(0), textureSize(img_tex[nonuniformEXT(mat)], 0)-1);
          vec4 diffcol = texelFetch(img_tex[nonuniformEXT(mat)], tc, 0);
          // if(any(greaterThan(diffcol.rgb, vec3(0.0))) || diffcol.a > 0.666)
          if(diffcol.a > 0.666)
            rayQueryConfirmIntersectionEXT(rq);
        }
      }
    }
    if(rayQueryGetIntersectionTypeEXT(rq, true) != gl_RayQueryCommittedIntersectionNoneEXT) ao ++;
#endif
  }
  // ao += 0.5*(rand.z + rand.w)-0.5; // dither
  ao = clamp(ao/samples, 0.0, 1.0);
  float edf = 5.0*pow(abs(dot(-ws, params.cam_w.xyz)), 30.0);
  return (1.0-ao) * rgb * abs(dot(ws,n)) * edf * vec3(50.0)/(ldist*ldist); // light with falloff
}

bool cast_ray(rayQueryEXT rq, vec3 x, vec3 w)
{
  rayQueryInitializeEXT(rq, rt_accel, gl_RayFlagsNoneEXT, 0xFF, x, 1e-3, w, 10000.0);
  while(rayQueryProceedEXT(rq))
  {
    if (rayQueryGetIntersectionTypeEXT(rq, false) == gl_RayQueryCandidateIntersectionTriangleEXT)
    {
      int instance_id = rayQueryGetIntersectionInstanceIdEXT(rq, false); // which of our ssbo
      int pi = rayQueryGetIntersectionPrimitiveIndexEXT(rq, false); // primitive inside instance
      vec3 b;
      b.yz = rayQueryGetIntersectionBarycentricsEXT(rq, false);
      b.x = 1.0-b.z-b.y;
      // if(min(b.x,min(b.y,b.z)) < 0.05) rayQueryConfirmIntersectionEXT(rq); // wireframe
      int i = 7*pi;
      uint mat = 0;
      vec2 st;
      if(instance_id == 0)
      {
        mat   = dynssbo.v[i+6]&0xffff;
        vec2 st0 = unpackHalf2x16(dynssbo.v[i+3]);
        vec2 st1 = unpackHalf2x16(dynssbo.v[i+4]);
        vec2 st2 = unpackHalf2x16(dynssbo.v[i+5]);
        st = mat3x2(st0, st1, st2) * b;
      }
      else
      {
        mat   = stcssbo.v[i+6]&0xffff;
        vec2 st0 = unpackHalf2x16(stcssbo.v[i+3]);
        vec2 st1 = unpackHalf2x16(stcssbo.v[i+4]);
        vec2 st2 = unpackHalf2x16(stcssbo.v[i+5]);
        st = mat3x2(st0, st1, st2) * b;
      }
      if(mat == 0xffff) 
      { // sky, nothing behind it, right?
        rayQueryConfirmIntersectionEXT(rq);
      }
      else
      {
        ivec2 tc = ivec2(textureSize(img_tex[nonuniformEXT(mat)], 0)*mod(st, vec2(1.0)));
        tc = clamp(tc, ivec2(0), textureSize(img_tex[nonuniformEXT(mat)], 0)-1);
        vec4 diffcol = texelFetch(img_tex[nonuniformEXT(mat)], tc, 0);
        if(diffcol.a > 0.666) rayQueryConfirmIntersectionEXT(rq);
      }
    }
  }
  return (rayQueryGetIntersectionTypeEXT(rq, true) == gl_RayQueryCommittedIntersectionTriangleEXT);
}

struct reservoir_t
{
  intersection_t inter; // descriptor of ponit on light source, reconstructs the next block:

  vec3  y;              // world space position of light source point
  vec3  Le;             // emission of that point
  vec3  n;              // shading normal

  float w_sum;          // sum of weights
  uint  M;              // number of samples so far
  float W;              // combined weight
};

reservoir_t reservoir_new()
{
  reservoir_t r;
  r.y = vec3(0);
  r.w_sum = 0.0;
  r.M = 0;
  r.W = 0;
  return r;
}

float ph(
    vec3 y,  // point on light
    vec3 ny, // shading normal on light
    vec3 Le, // emission
    vec3 x,  // shading point
    vec3 nx) // shading normal
  // TODO: bsdf
{ // return ideal sampling probability density for this light sample point
  vec3 d = y-x;
  float r2 = dot(d,d);
  d = normalize(d);
  return length(Le) * max(0, dot(d, nx))*max(0, dot(-d, ny))/max(1e-6, r2);
}

float
reservoir_W(
    reservoir_t r,
    vec3 x, vec3 n)
{
  if(r.M == 0) return 0.0;
  return r.w_sum / r.M / ph(r.y, r.n, r.Le, x, n);
}

void
reservoir_combine(
    inout reservoir_t r,
    reservoir_t       r2,
    vec3              x,    // shading point x
    vec3              n,    // shading point n
    float             rand)
{
  float w = ph(r2.y, r2.n, r2.Le, x, n)*r2.W*r2.M;
  r.w_sum += w;
  r.M     += r2.M;
  r.w_sum = clamp(r.w_sum, 0, 5000); // seems necessary to avoid overflow
  r.M     = clamp(r.M, 0, 5000);
  if(rand < w / r.w_sum)
  {
    r.inter = r2.inter;
    r.y     = r2.y;
    r.n     = r2.n;
    r.Le    = r2.Le;
    r.W     = reservoir_W(r, x, n);
  }
}

// we need to add the reservoir as phq(r.y)/phq'(r.x) * r.w_sum
// which is equivalent to phq(r.y) * r.M * r.W (and we'll multiply phq on load)
uvec4 reservoir_encode(reservoir_t r)
{
  return uvec4(
      (r.inter.instid & 0x3) | (r.inter.primid << 2),
      r.inter.uv,
      r.M,
      floatBitsToUint(r.W));
}

reservoir_t reservoir_decode(uvec4 enc, vec3 x)
{
  reservoir_t r;
  r.inter.instid = int(enc.x & 0x3);
  r.inter.primid = int(enc.x >> 2);
  r.inter.uv = enc.y;
  r.M = enc.z;
  r.W = uintBitsToFloat(enc.w);
  material_info_t m = prepare_material_info(x, vec3(666), r.inter);
  r.y  = m.x;
  r.n  = m.n;
  r.Le = m.emission;
  return r;
}

void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_irradiance)))) return;

  // uint seed = 19937 * global.frame;
  // today my bluenoise textures are borken. wtf.
  uint seed = 13370000 * ipos.x + ipos.y * 70000 + global.frame * 19937;
  const ivec2 rp = ivec2(mod(ipos, textureSize(img_blue, 0)));

  vec3 alb = vec3(0.0); // albedo
  vec3 irr = vec3(0.0); // estimator for incoming "irradiance", i.e. everything divided by albedo

  reservoir_t res = reservoir_new(); // init zero
  for(int s=0;s<params.spp;s++)
  {
    vec3 lpos = vec3(0.0); // torch light pos, depending on camera
    intersection_t inter;
    material_info_t m0, m1;
    float total_dist = 0.0;
    vec4 rand = xrand(seed, rp);
    seed = uint(70000 * rand.x);
    float frame = global.frame;// + 0.5*rand.x; // 180 degree shutter
    vec3 rgb = vec3(1.0);
    vec3 w;       // ray direction
    float pdf_w;  // pdf of directional sampling
    { // camera setup:
      m0.x = params.cam_x.xyz;
      vec3 f = params.cam_w.xyz;
      vec3 up = vec3(0, 0, 1);
      vec3 r = normalize(cross(f, up));
      vec3 t = normalize(cross(f, r)) * float(imageSize(img_irradiance).y)/float(imageSize(img_irradiance).x);

      lpos = m0.x + 1*f + 10*up + 20*r;

      vec2 off = filter_bh_sample(rand.yz);
      vec2 uv = (ipos+off)/imageSize(img_irradiance) - 0.5;
      // vec2 uv = (ipos+0.5)/imageSize(img_irradiance) - 0.5;
      w = normalize(0.45*f + r*uv.x + t*uv.y);
      m0.n = f;
      pdf_w = 1.0; // whatever we will not be light tracing here
    }
    for(int b=0;b<2;b++) // bounces
    {
      rayQueryEXT rq;
      if(cast_ray(rq, m0.x, w))
      { // ray intersected geometry, init material state and tangent frame
        const float t = rayQueryGetIntersectionTEXT(rq, true);
        total_dist += t;
        const float T = exp(-t * 3.);
        rgb *= mix(vec3(0.2, 0.4, 0.9), vec3(1.0), T);
        intersection_t inter = prepare_intersection(rq);
        m1 = prepare_material_info(m0.x, w, inter);

        // vertex area measure pdf of x (new vertex)
        float pdf = pdf_w * 1.0/dot(m1.x-m0.x,m1.x-m0.x) * max(0, dot(m0.n, w)) * max(0, dot(m1.n, -w));

        // handle intersection:
        // * accumulate direct albedo and indirect irradiance channels
        // * first time: load nee state from buffer
        // * successful nee sample: store nee state in registers
        rand = xrand(seed, rp);
        if(b == 0 && s == 0)
        { // first sample primary hit combines spatiotemporal reservoirs (surroundings of pixel in last frame)
          vec2 mv = texelFetch(img_mv, ipos, 0).rg;
          const ivec2 off[] = {
            ivec2(-1, -4), ivec2(4, -1), ivec2(1,  4), ivec2(-4, 1),
            ivec2(-2, -1), ivec2(0, -1), ivec2(1, -2),
            ivec2(-1,  0), ivec2(0,  0), ivec2(1,  0),
            ivec2(-1,  2), ivec2(0,  1), ivec2(2,  1)};
          for(int i=0;i<13;i++)
          {
            rand = xrand(seed, rp);
            reservoir_t r2 = reservoir_decode(texelFetch(img_nee_in, ivec2(ipos+mv+off[i]), 0), m1.x);
            reservoir_combine(res, r2, m1.x, m1.n, rand.x);
          }
        }
        if(any(greaterThan(m1.emission, vec3(0.0))))
        { // have >0 radiance sample
          if(b == 1) // on 3rd vertex
          { // update nee sampling state
            reservoir_t r2 = reservoir_new();
            r2.y = m1.x; r2.n = m1.n; r2.Le = m1.emission;
            r2.M = 1; r2.W = 1.0/pdf; r2.inter = inter;
            reservoir_combine(res, r2, m0.x, m0.n, rand.z);
          }
          if(b >= 1) // 3rd vertex or more
          { // accumulate indirect irradiance
            irr += rgb * m1.emission / pdf_w;
          }
          if(b == 0) // on 2nd vertex
          { // directly visible light source
            irr += 0.01; // but be sure that albedo * irradiance stays put.
            alb += 100 * m1.emission;
          }
          break; // no indirect light on emitters
        }
        else
        { // no light source
          if(b == 0) alb += m1.albedo; // accumulate directly visible albedo
          if(b == 1) { res.M = 0; res.W = 0.0; } // not visible after all so it seems, clear reservoir
        }



#if 0 // next event estimation to torch:
        irr += nee_torch(lpos, m1.x, rgb, m1.n, seed, rp);
#endif


#if 1
        // sample direction outgoing from m1.x according to the reservoir
        // use res.y as point to aim at, estimator is f(res.y)*res.W
        float W = res.W;//reservoir_W(res, m1.x, m1.n);
        const float a = 0.2;
        if(global.frame > 10 && W > 0 && rand.w > a)
        {
          w = normalize(res.y - m1.x);
          float G = 1.0/dot(res.y-m1.x,res.y-m1.x) * max(0, dot(m1.n, w)) * max(0, dot(res.n, -w));
          pdf_w = (1.0-a)/(W*G); // convert to directional pdf (projected solid angle)
          rgb *= 1.0/radians(180); // bsdf without albedo
        }
        else
#endif
        { // sample independent new ray direction
          w = sample_cos(rand.xy);
          w = w.x * m1.du + w.y * m1.dv + w.z * m1.n;
          w = normalize(w); // paranoia/numerical jitter over bounces
          pdf_w = a/radians(180); // uniform projected solid angle
          rgb *= 1.0/radians(180);  // bsdf without albedo
        }
        m0 = m1; // advance path vertex
      }
      else
      { // envmap, never reached for closed quake maps
        // irr += envmap(w).rgb; // accumulate nothing to avoid light leaks
        // vec3 diffcol = texture(img_tex[0], w.xy).rgb;
        // acc += rgb * diffcol * 1000.0 * vec3(0.2, 0.4, 0.9);
        // if(b == 0) aov = (w+vec3(1.0))/2.0;
        break;
      }
    }
  }
  irr /= params.spp;
  alb /= params.spp;

  imageStore(img_nee_out,    ipos, reservoir_encode(res));
  imageStore(img_irradiance, ipos, vec4(40*irr, 1));
  imageStore(img_albedo,     ipos, vec4(alb, 1));
}

