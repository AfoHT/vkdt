#version 460
#extension GL_GOOGLE_include_directive    : enable

#include "shared.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 1) uniform params_t
{
  vec4  mul;               // camera white balance (r,g,b, exposure)
  mat3  cam_to_rec2020;    // camera matrix
  uvec4 N;                 // number of patches < 20
  vec4  coef[22];          // xy RBF positions, zw coefs
  float temp;              // colour temperature for wb 0:2856 1:6500
  uint  colour_mode;       // 0-matrix 1-clut
} params;

layout(push_constant, std140) uniform push_t
{
  int have_clut;
} push;


layout( // input
    set = 1, binding = 0
) uniform sampler2D img_in;

layout( // output
    set = 1, binding = 1
) uniform writeonly image2D img_out;

layout( // if have_clut, the colour lookup table is here
    set = 1, binding = 2
) uniform sampler2D img_clut;

vec3 // return adapted rec2020
cat16(vec3 rec2020_d65, vec3 rec2020_w)
{
  // TODO: concat these with xyz/rec2020 in python and bring back the results? are constants folded enough anyways?
  // these are the CAT16 M^{-1} and M matrices.
  // we use the standalone adaptation as proposed in
  // Smet and Ma, "Some concerns regarding the CAT16 chromatic adaptation transform",
  // Color Res Appl. 2020;45:172â€“177.
  // these are XYZ to cone-like
  const mat3 M16i = transpose(mat3(
       1.86206786, -1.01125463,  0.14918677,
       0.38752654,  0.62144744, -0.00897398,
      -0.01584150, -0.03412294,  1.04996444));
  const mat3 M16 = transpose(mat3(
       0.401288, 0.650173, -0.051461,
      -0.250268, 1.204414,  0.045854,
      -0.002079, 0.048952,  0.953127));
  const mat3 rec2020_to_xyz = mat3(
    6.36958048e-01, 2.62700212e-01, 4.20575872e-11,
    1.44616904e-01, 6.77998072e-01, 2.80726931e-02,
    1.68880975e-01, 5.93017165e-02, 1.06098506e+00);

  const vec3 cl_d65 = M16 * rec2020_to_xyz * vec3(1);
  const vec3 cl_w   = M16 * rec2020_to_xyz * rec2020_w;
  vec3 cl = M16 * rec2020_to_xyz * rec2020_d65;
  cl *= cl_w / cl_d65;
  return inverse(rec2020_to_xyz) * M16i * cl;
}


float
kernel(vec2 ci, vec2 p)
{
  // gaussian kernel
  float r2 = .99 * dot(ci-p, ci-p) + 1e-3;
  // return exp(-0.5*r2/0.0025);
  // return exp(-0.5*r2/0.002);
  // thinplate spline kernel
  return r2 * log(r2);
}

void tri2quad(inout vec2 tc)
{
  tc.y = tc.y / (1.0-tc.x);
  tc.x = (1.0-tc.x)*(1.0-tc.x);
}

void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  vec3 rgb = texelFetch(img_in, ipos, 0).rgb;

  if(params.colour_mode == 0 || push.have_clut == 0)
  { // matrix + wb
    rgb *= params.mul.rgb; 
    rgb  = params.cam_to_rec2020 * rgb;
  }
  else
  { // clut
    float b = rgb.r+rgb.g+rgb.b;
    vec2 tc = rgb.rb/b;
    tri2quad(tc);
    tc.x /= 3.0;
    vec4 rbrb = vec4(texture(img_clut, tc).xy, texture(img_clut, tc+vec2(2.0/3.0, 0.0)).xy);
    vec2 L2 = texture(img_clut, tc + vec2(1.0/3.0, 0.0)).xy;
    float L = mix(L2.x, L2.y, params.temp);
    vec2 rb = mix(rbrb.xy, rbrb.zw, params.temp);
    rgb = vec3(rb.x, 1.0-rb.x-rb.y, rb.y);
    rgb *= L * b;

    rgb = cat16(rgb, params.mul.rgb);
  }

  rgb *= params.mul.w; // exposure correction

  if(params.N.x > 0)
  {
    const float b = dot(rgb, vec3(1));
    rgb /= b;
#if 1 // plain rb
    vec2 ci = rgb.xz;
#else // log(g/r) log(g/b)
    vec2 ci = log(rgb.g/(1e-8+rgb.rb));
#endif
    // now rbf part:
    vec2 co = mat2(params.coef[params.N.x+0].zw, params.coef[params.N.x+1].zw) * ci;
    for(int i=0;i<params.N.x;i++)
      co += params.coef[i].zw * kernel(ci, params.coef[i].xy);

#if 1 // plain rb
    rgb.xz = co;
    rgb.y = 1.0 - rgb.x - rgb.z;
#else // log
    rgb.xz = rgb.y/exp(co)-1e-8;
    rgb /= dot(rgb, vec3(1));
#endif
    rgb *= b; // keep brightness constant
  }

  imageStore(img_out, ipos, vec4(rgb, 1));
}

