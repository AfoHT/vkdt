#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable
#extension GL_EXT_shader_16bit_storage    : enable
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : enable
#include "shared.glsl"
#include "config.h"

// we are processing tiles of WD x HT at a time.
// a workgroup of threads is created, one for each
// because then a 4x4x4 matrix muladd (tensor cores) can read a 4x4 matrix (4 adjacent pixels x 4 input channels) and multiply by 4x4 weights (input channels x output channels for given conv pos) and add to result (4 adjacent pixels x 4 output channels)

// we have max 16 output channels
layout(local_size_x = DT_CNN_TILE_WD, local_size_y = DT_CNN_TILE_HT, local_size_z = 4) in;

// layout(std140, set = 0, binding = 1) uniform params_t
// { } params;

layout( // input texture
    set = 1, binding = 0
) uniform sampler2D img_in;

layout( // weights
    set = 1, binding = 1
) uniform sampler2D img_wgt;

layout( // output buffer
    set = 1, binding = 2
) uniform writeonly image2D img_out;

// intermediate layers, allocated for the maximum number of outputs
shared f16vec4 layer[4*DT_CNN_TILE_WD*DT_CNN_TILE_HT];


f16vec4 read_bias(
    uint ic, // number of input channels
    uint o,  // the output channel (start index of group of 4)
    uint y0) // the offset of the current layer
{
  return f16vec4(texelFetch(img_wgt, ivec2(9*ic, y0 + o/4), 0));
}

// read the weight matrix for a given convolution position k<9.
// returns 4x4 to be multiplied against column vectors of inputs
// arranged as [i, i+1, i+2, i+3]^t to yield output deltas to
// be summed onto [o, o+1, o+2, o+3]^t
f16mat4 read_mat(
    uint i,   // the input channel to process, start of a group of 4
    uint o,   // the output channels to process, start of a group of 4
    uint k,   // the 3x3 convolution mask index < 9
    uint y0)  // the offset in the weights texture for this layer
{
  // k += 9*i
  // ir = i - ip/4;
  // y = y0 + o/4
  // now read texture rgba at (k, y0), (k+9, y0), (k+18, y0), (k+27, y0)
  // pack into matrix where column vectors are rgba (for output channels)
  // return that
  return f16mat4(1.0);
}

// TODO: first implement "scalar" version reading/writing one channel at a time
// TODO: then implement 4x4 version reading/writing by weight matrix
// TODO: then use tensor cores
// TODO: try ssbo instead of texture, reading f16 directly
void
main()
{
  ivec2 ipos =
    ivec2(gl_WorkGroupID.xy * ivec2(
        DT_CNN_TILE_WD-2*DT_CNN_BORDER,
        DT_CNN_TILE_HT-2*DT_CNN_BORDER));
  // if start of tile is out of image we have nothing to do:
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;
  ipos += ivec2(gl_LocalInvocationID.xy) - ivec2(DT_CNN_BORDER, DT_CNN_BORDER); // add offset within the tile

  // invocation id.z is the output channel/4
  const uint cout = gl_LocalInvocationID.z;

  // initially fill 6 channels of layer[] with orig + 5x5 blur, sourced from img_in.
  const uint tidx = gl_LocalInvocationID.x + gl_WorkGroupSize.x * gl_LocalInvocationID.y;
  // XXX TODO: try different order in shared memory (tile first, then output)
  { // 5x5 scope
    uint idx = 2*tidx + cout;
    f16vec4 res = f16vec4(0.0);
    if(cout == 0) res = f16vec4(texture(img_in, (ipos+0.5)/vec2(textureSize(img_in, 0))));
    if(cout == 1)
    for(int j=-2;j<=2;j++) for(int i=-2;i<=2;i++)
    {
      const float16_t wgt[5] = {float16_t(2./16.), float16_t(4./16.), float16_t(6./16.), float16_t(4./16.), float16_t(2./16.)};
      f16vec4 tex = f16vec4(texture(img_in, (ipos+0.5)/vec2(textureSize(img_in, 0))));
      res += wgt[j+2]*wgt[i+2] * tex;
    }
    layer[idx] = res;
  }

  int ci_cnt = 6;  // number of input channels
  int co_cnt = 16; // number of output channels
  int off = 1;     // current y coordinate in weights texture

  // XXX TODO: special case for first time with padding for weights?
  // XXX TODO: write the texture padded already?

  for(int l=0;l<15;l++)
  { // inner 3x3 scope: C1..C15
    uint idx = (co_cnt+3)/4 * tidx + cout;
    f16vec4 res = read_bias(ci_cnt, 4*cout, off);
    for(int j=-1;j<=1;j++) for(int i=-1;i<=1;i++) for(int ip=0;ip<(ci_cnt+3)/4;ip++)
    {
      f16mat4 m = read_mat(3*(j+1)+i+1, ip, 4*cout, off);
      res += m * layer[
        ip + ci_cnt * (
        clamp(gl_LocalInvocationID.x+i,0,DT_CNN_TILE_WD-1) + gl_WorkGroupSize.x *
        clamp(gl_LocalInvocationID.y+j,0,DT_CNN_TILE_HT-1))];
    }
    // apply leaky relu
    res *= mix(f16vec4(1.0), f16vec4(0.05), lessThan(res, f16vec4(0.0)));
    barrier(); // wait until everybody has their result ready
    layer[idx] = res;
    // update ci_cnt and co_cnt
    barrier(); // now all results are in place, carry on.
    ci_cnt = co_cnt;
    co_cnt = 16;
    off += 4;
  }

#if 0
  { // TODO: last layer C16 with three outputs and no relu
    co_cnt = 3;
    uint idx = (co_cnt+3)/4 * tidx + cout;
    f16vec4 res = f16vec4(0.0);
    if(cout <= co_cnt/4) res = read_bias(ci_cnt, 4*cout, off);
    if(cout <= co_cnt/4)
    for(int j=-1;j<=1;j++) for(int i=-1;i<=1;i++) for(int ip=0;ip<(ci_cnt+3)/4;ip++)
    { // last 3x3
      f16mat4 m = read_mat(3*(j+1)+i+1, 4*ip, 4*cout, off);
      res += m * layer[
        ip + ci_cnt * (
        clamp(gl_LocalInvocationID.x+i,0,DT_CNN_TILE_WD-1) + gl_WorkGroupSize.x *
        clamp(gl_LocalInvocationID.y+j,0,DT_CNN_TILE_HT-1))];
    }
    else if(cout == 1) for(int j=-2;j<=2;j++) for(int i=-2;i<=2;i++)
    { // regenerate above 5x5 blur for summing it back
      const float16_t wgt[5] = {float16_t(2./16.), float16_t(4./16.), float16_t(6./16.), float16_t(4./16.), float16_t(2./16.)};
      f16vec4 tex = f16vec4(texture(img_in, (ipos+0.5)/vec2(textureSize(img_in, 0))));
      res += wgt[j+2]*wgt[i+2] * tex;
    }
    barrier();
    idx = (co_cnt+3)/4 * tidx + cout; // write index
    layer[idx] = res;
    barrier();
  }
#endif

  if(cout == 0)
  {
    uint idx = 2 * tidx;
    // sum back to blurred input
    vec3 rgb = vec3(layer[idx].rgb) + vec3(layer[idx+1].rgb);
    // write back to output texture
    if(all(greaterThanEqual(gl_LocalInvocationID.xy, uvec2(DT_CNN_BORDER))) &&
        all(lessThan(gl_LocalInvocationID.xy, uvec2(DT_CNN_TILE_WD-DT_CNN_BORDER, DT_CNN_TILE_HT-DT_CNN_BORDER))) &&
        all(lessThan(ipos, imageSize(img_out))))
      imageStore(img_out, ipos, vec4(rgb, 1));
  }
}
