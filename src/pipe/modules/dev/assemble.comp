#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable

#include "shared.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 1) uniform params_t
{
  float strength;
  float chroma;
  float luma;
  // TODO: vec4 black and vec4 white
  // TODO: filters for raw vs rgb (which has no black/white)
  float black;
  float noise_a;
  float noise_b;
} params;

// TODO: implement half/doub kernels for raw (one level of decimated wavelets, steal from hilite)
// TODO: use wb + yuv matrix for preconditioning, shrink colour separately (and more aggressively)

// TODO: maybe use vanilla params + push constants for black/white/filters/wb/noise_*?
// layout(push_constant, std140) uniform push_t
// {
//   int level;
// } push;

// 5 input scales
layout( set = 1, binding = 0) uniform sampler2D img_s0; // original image
layout( set = 1, binding = 1) uniform sampler2D img_s1; // one downsampling step
layout( set = 1, binding = 2) uniform sampler2D img_s2; // ..
layout( set = 1, binding = 3) uniform sampler2D img_s3;
layout( set = 1, binding = 4) uniform sampler2D img_s4; // four downsampling steps

layout( // output
    set = 1, binding = 5
) uniform writeonly image2D img_out;

void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  ivec2 sz = textureSize(img_s0, 0).xy;

  // go through all levels same as downsampling would, swizzling coordinates
  // on the go as done in down.comp. then pick up the scales accordingly.
  vec3 down4;
  vec3 orig = texelFetch(img_s0, ipos, 0).rgb;
  { // scope for registers
    ivec2 esi = ipos;

    vec3 down0 = orig;
    // TODO: consider 2px padding radius for next iteration and mirror repeat!
    esi = esi / 2 + ivec2(esi.x & 1, esi.y & 1) * sz/2;
    vec3 down1 = texelFetch(img_s1, esi, 0).rgb;
    esi = esi / 2 + ivec2(esi.x & 1, esi.y & 1) * sz/2;
    vec3 down2 = texelFetch(img_s2, esi, 0).rgb;
    esi = esi / 2 + ivec2(esi.x & 1, esi.y & 1) * sz/2;
    vec3 down3 = texelFetch(img_s3, esi, 0).rgb;
    esi = esi / 2 + ivec2(esi.x & 1, esi.y & 1) * sz/2;
    down4 = texelFetch(img_s4, esi, 0).rgb;

    // compute wavelet coefficients for this pixel
    // normalise these by dividing out expected noise std dev:
    float sigma = sqrt(params.noise_a + 65535.0*max(down2.g - params.black, 0.0)*params.noise_b)/65535.0;
    // Var(aX) = a^2 * Var(X), so the factors of our filter taps come in squared here:
    // var band = 
    //  (t*t + (1.0-t)*(1.0-t)*4.0/16.0*(
    //  0.2*0.4*0.2*0.4 + 0.2*0.6*0.2*0.6 + 0.8*0.4*0.8*0.4 + 0.8*0.6*0.8*0.6)) * base var
    // => sigma' ~= 0.29165 * base sigma
    const float b1 = 0.291652;
    const float b2 = 0.085061;
    const float b3 = 0.024808;
    down0 = (down0 - down1)/(sigma);
    down1 = (down1 - down2)/(sigma*b1);
    down2 = (down2 - down3)/(sigma*b2);
    down3 = (down3 - down4)/(sigma*b3);

    // xi-squared statistic for iid unit variance:
    vec3 xi2 = down0*down0 + down1*down1 + down2*down2 + down3*down3 - 4.0; // * (n-1) = 3 really
    // TODO: compute probability that these are indeed iid wrt some p value
    // TODO: compute wavelet transform completely in yuv and only protect y edges?
    // vec3 xi2 = abs(down0) + abs(down1) + abs(down2) + abs(down3);

    // wavelet shrinkage and re-assembly:
    // vec3 test = exp(- 0.002*xi2); // L1
    vec3 test = exp(- 0.004*sqrt(xi2)); // Xi2
    // bayes shrink would be T = sigma_noise^2 / sigma_signal
    // ?// consider that sigma_channel^2 scales as 1/f^2 with frequency f for natural images
    // ?// we calibrate for black..white expected contrast (rest up to strength param)
    // ?// and are left with sig_noise * f
    // we assume sigma_noise = frac * sigma_signal and cancel the two.
    // since we rescaled the bands to unit noise variance, the threshold is
    // just a (user) constant and the edge shielding term:
    float thrs = params.strength * 3.0 * dot(test, vec3(1.0));
    down4 += sigma * b3 * sign(down3) * max(abs(down3) - thrs, vec3(0.0));
    down4 += sigma * b2 * sign(down2) * max(abs(down2) - thrs, vec3(0.0));
    down4 += sigma * b1 * sign(down1) * max(abs(down1) - thrs, vec3(0.0));
    down4 += sigma      * sign(down0) * max(abs(down0) - thrs, vec3(0.0));
  }

  // TODO: maybe transform this before wavelets and then double the colour threshold or so
  // this is for srgb not rec2020, but whatever
  mat3 rgb_to_yuv = mat3(
      0.299, -0.147, 0.615,
      0.587, -0.289, -0.515,
      0.114, 0.436, -0.100);

  vec3 yuv1 = rgb_to_yuv * down4;
  vec3 yuv0 = rgb_to_yuv * orig;
  vec3 rgb = inverse(rgb_to_yuv) * vec3(mix(yuv0.x, yuv1.x, params.luma), mix(yuv0.yz, yuv1.yz, params.chroma));

  imageStore(img_out, ipos, vec4(rgb, 1));
}

