#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable

#include "shared.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 1) uniform params_t
{
  float strength;
} params;

layout(push_constant, std140) uniform push_t
{
  vec4 wb;
  vec4 black;
  vec4 white;
  ivec4 crop;
  uint filters;
} push;

layout( // input uint16 buffer rggb
    set = 1, binding = 0
) uniform sampler2D img_in;

layout( // input f16 buffer rgb
    set = 1, binding = 1
) uniform sampler2D img_coarse;

layout( // output f16 buffer rggb
    set = 1, binding = 2
) uniform writeonly image2D img_out;

// upsample back to mosaic. this is either 3x3 or 2x2, depending on filters.
// runs on coarse resolution.
// our goal is to do one scale of decimated wavelet denoising, while keeping
// clipped pixels clipped (these will be copied straight to the output)
void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  vec3 upsm = texelFetch(img_coarse, ipos, 0).rgb;

  if(push.filters == 9)
  {
    // swap red and blue channels according to sensor layout
    if(((ipos.x + ipos.y + push.crop.x + push.crop.y) & 1) == 0)
      upsm.rgb = upsm.bgr;
    // get original input texels
    float c0 = texelFetch(img_in, push.crop.xy + 3*ipos, 0).r;
    float c1 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(0,1), 0).r;
    float c2 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(0,2), 0).r;
    float c3 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(1,0), 0).r;
    float c4 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(1,1), 0).r;
    float c5 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(1,2), 0).r;
    float c6 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(2,0), 0).r;
    float c7 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(2,1), 0).r;
    float c8 = texelFetch(img_in, push.crop.xy + 3*ipos+ivec2(2,2), 0).r;

    // do wavelet shrinkage with these channels.
    // make sure to keep clipped (>= white)!
    // TODO: use black and white according to correct channel!
#define SHRINK(A, B) {\
      A = max(0, (A - push.black.x)/(push.white.x - push.black.x));\
      if(A <= 1000.0) { \
        float wav = A - B;\
        A = B + sign(wav) * max(0.0, abs(wav) - T);\
      }\
    }

    // TODO: push constant: noise_ab
    // TODO: evaluate noise model here, too
    // TODO: use chroma slider to derive colour threshold by taste
    // TODO: use luma slider to blend in original greens
    // TODO: need explicit routing of raw -> assemble?

    // TODO: colour channel threshold
    float T = 0.01;// XXX
    SHRINK(c1, upsm.r)
    SHRINK(c7, upsm.r)
    SHRINK(c3, upsm.b)
    SHRINK(c5, upsm.b)

    // TODO: T = green threshold
    T = 0.001; // XXX
    SHRINK(c0, upsm.g)
    SHRINK(c2, upsm.g)
    SHRINK(c4, upsm.g)
    SHRINK(c6, upsm.g)
    SHRINK(c8, upsm.g)
    // TODO: plus blend in original greens by luma weight
#undef SHRINK
    // TODO: noise model needs adjustment for filters

    imageStore(img_out, 3*ipos,            vec4(vec3(c0), 1));
    imageStore(img_out, 3*ipos+ivec2(0,1), vec4(vec3(c1), 1));
    imageStore(img_out, 3*ipos+ivec2(0,2), vec4(vec3(c2), 1));
    imageStore(img_out, 3*ipos+ivec2(1,0), vec4(vec3(c3), 1));
    imageStore(img_out, 3*ipos+ivec2(1,1), vec4(vec3(c4), 1));
    imageStore(img_out, 3*ipos+ivec2(1,2), vec4(vec3(c5), 1));
    imageStore(img_out, 3*ipos+ivec2(2,0), vec4(vec3(c6), 1));
    imageStore(img_out, 3*ipos+ivec2(2,1), vec4(vec3(c7), 1));
    imageStore(img_out, 3*ipos+ivec2(2,2), vec4(vec3(c8), 1));
  }
  else
  {
    // reads : w z -> r g
    //         x y    g b
    vec4 c = textureGather(img_in, (push.crop.xy + 2*(ipos+.5))/vec2(textureSize(img_in, 0)), 0);
    // XXX this is hilite code, did not touch it!!
    // FIXME:
#if 0
    float ming = min(c.x, c.z);
    float scale;

    // find by blurry image
    if     (upsm.r < upsm.g && upsm.r < upsm.b)  scale = c.w /max(0.0001, upsm.r);
    else if(upsm.g < upsm.r && upsm.g < upsm.b)  scale = ming/max(0.0001, upsm.g);
    else /*(upsm.b < upsm.g && upsm.b < upsm.r)*/scale = c.y /max(0.0001, upsm.b);

    if(c.x >= white ||
       c.y >= white ||
       c.z >= white ||
       c.w >= white)
      c = scale * upsm.gbgr;
#endif
    imageStore(img_out, 2*ipos,            vec4(c.w));
    imageStore(img_out, 2*ipos+ivec2(1,0), vec4(c.z));
    imageStore(img_out, 2*ipos+ivec2(0,1), vec4(c.x));
    imageStore(img_out, 2*ipos+ivec2(1,1), vec4(c.y));
  }
}
