#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable
#extension GL_EXT_ray_tracing             : enable
#extension GL_EXT_ray_query               : enable

#include "shared.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 0) uniform global_t
{ 
  int frame;
} global;

layout(std140, set = 0, binding = 1) uniform params_t
{ 
  float angle;
} params;

// TODO: would this be faster using a textureBuffer instead of an ssbo?
layout(std430, set = 1, binding = 0) buffer ssbo_t
{
  uvec2 v[]; // variable-length list of bytes encoding vertices and indices
} ssbo;

layout( // output f16 buffer rgb
    set = 1, binding = 1
) uniform writeonly image2D img_out;

layout(
    set = 2, binding = 0
) uniform accelerationStructureEXT rt_accel;

#if 1 // TODO: put stuff like this in montecarlo.glsl or so
#if 0
// uniformly sample the unit sphere, p = 1/4pi
static inline void sample_sphere(float *x, float *y, float *z, const float x1, const float x2)
{
  *z = 1.f - 2.f*x1;
  const float r = sqrtf(1.f - *z**z);
  const float phi = 2.f*M_PI*x2;
  *x = r * cosf(phi);
  *y = r * sinf(phi);
}

// sample hemisphere uniformly, p = 1/2pi
static inline void sample_hemisphere(float *x, float *y, float *z, const float x1, const float x2)
{
  *z = 1.f - x1;
  const float r = sqrtf(1.f - *z**z);
  const float phi = 2.f*M_PI*x2;
  *x = r * cosf(phi);
  *y = r * sinf(phi);
}

// sample hemisphere, cos^k lobe, p = cos^k(theta) (k+1)/2pi
static inline void sample_cos_k(float *x, float *y, float *z, const float k, const float x1, const float x2)
{
  const float r1 = x1 * 2.0f * M_PI;
  const float cos_theta = powf(1.0f - x2, 1.0f/(k+1));
  const float sin_theta = sqrtf(MAX(0.0f, 1.0f - cos_theta*cos_theta));
  *x = cosf(r1) * sin_theta;
  *y = sinf(r1) * sin_theta;
  *z = cos_theta;
}
#endif

// sample hemisphere, cos lobe, p = cos(theta)/pi
vec3 sample_cos(vec2 x)
{
  float su = sqrt(x.x);
  return vec3(su*cos(2.0*3.1415*x.y), su*sin(2.0*3.1415*x.y), sqrt(1.0 - x.x));
}

float xrand(inout uint seed)
{ // Algorithm "xor" from p. 4 of Marsaglia, "Xorshift RNGs"
  seed ^= seed << 13;
  seed ^= seed >> 17;
  seed ^= seed << 5;
  return seed / 4294967296.0;
}
#endif

// 32-bit normal encoding from Journal of Computer Graphics Techniques Vol. 3, No. 2, 2014
// A Survey of Efficient Representations for Independent Unit Vectors
// almost like oct30, but our error is = 0.00077204 avg = 0.00010846 compared to oct32P 0.00246 0.00122
// i'm thinking maybe because we use a fixed point quantization (only multiples of 2 are mul/divd here)
// this also enables us to precisely encode (1 0 0) vectors.
vec3 geo_decode_normal(const uint enc)
{
  vec2 projected = 2.0*unpackSnorm2x16(enc);
  vec3 vec = vec3(projected, 1.0-abs(projected.x)-abs(projected.y));
  if(vec.z < 0.0)
  {
    float oldX = vec.x;
    vec.x = (1.0 - abs(vec.y)) * ((oldX  < 0.0) ? -1.0 : 1.0);
    vec.y = (1.0 - abs(oldX))  * ((vec.y < 0.0) ? -1.0 : 1.0);
  }
  return normalize(vec);
}


void prepare_intersection(
    rayQueryEXT rq,
    vec3 w,
    inout vec3 x,
    out vec3 n,
    out vec2 st)
{
  // access and unpack geometry data
  uint pi = 3*rayQueryGetIntersectionPrimitiveIndexEXT(rq, true);
  uvec2 p0 = ssbo.v[pi+0];
  uvec2 p1 = ssbo.v[pi+1];
  uvec2 p2 = ssbo.v[pi+2];
  uint mat = p0.x >> 24;
  uint vi0 = p0.x & 0xffffffu;
  uint vi1 = p1.x & 0xffffffu;
  uint vi2 = p2.x & 0xffffffu;
  uvec4 u0 = uvec4(ssbo.v[2*vi0+0], ssbo.v[2*vi0+1]);
  uvec4 u1 = uvec4(ssbo.v[2*vi1+0], ssbo.v[2*vi1+1]);
  uvec4 u2 = uvec4(ssbo.v[2*vi2+0], ssbo.v[2*vi2+1]);
  vec3 n0 = geo_decode_normal(u0.w);
  vec3 n1 = geo_decode_normal(u1.w);
  vec3 n2 = geo_decode_normal(u2.w);
  vec3 v0 = uintBitsToFloat(u0.xyz);
  vec3 v1 = uintBitsToFloat(u1.xyz);
  vec3 v2 = uintBitsToFloat(u2.xyz);
  vec3 b;
  b.yz = rayQueryGetIntersectionBarycentricsEXT(rq, true);
  b.x = 1.0-b.z-b.y;
#if 0
  float t = rayQueryGetIntersectionTEXT(rq, true);
  x += t*w;
#else
  x = b.x * v0 + b.y * v1 + b.z * v2;
#endif
  // x.x = pi / 1000.0;
  n = b.x * n0 + b.y * n1 + b.z * n2;
  n = normalize(n);
  st = unpackSnorm2x16(p0.y); // TODO: interpolate too
}

void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  vec3 rgb = vec3(10.0); // init to constant background colour
  uint seed = 133700000 * ipos.x + ipos.y * 70000 + global.frame * 19937;

  float frame = global.frame + 0.5*xrand(seed); // 180 degree shutter
  vec3 x, w, n; // ray position, direction, hit normal
  vec2 st;      // texture coordinates
  { // camera setup:
    float angle = params.angle + frame * 0.002;
    x = 2.7 * vec3(sin(angle * 6.28), 0.3, cos(angle * 6.28));
    vec3 to = vec3(0, 0.5, 0);
    vec3 up = vec3(0, 1, 0);
    vec3 f = normalize(to-x);
    vec3 r = normalize(cross(f, up));
    vec3 t = normalize(cross(f, r));

    vec2 uv = (ipos+0.5)/imageSize(img_out) - 0.5;
    w = normalize(0.45*f + r*uv.x + t*uv.y);
  }

  for(int i=0;i<3;i++)
  {
    rayQueryEXT rq;
    rayQueryInitializeEXT(rq, rt_accel,
        gl_RayFlagsNoneEXT, //gl_RayFlagsTerminateOnFirstHitEXT,// | gl_RayFlagsOpaqueEXT | gl_RayFlagsSkipClosestHitShaderEXT,
        0xFF, x, 1e-3, w, 1000.0);
    while(rayQueryProceedEXT(rq)) {
      // if (rayQueryGetIntersectionTypeEXT(rq, false) == gl_RayQueryCandidateIntersectionTriangleEXT)
      // rayQueryConfirmIntersectionEXT(rq);
    }
    // if(rayQueryGetIntersectionTypeEXT(rq, true) != gl_RayQueryCommittedIntersectionNoneEXT)
    if(rayQueryGetIntersectionTypeEXT(rq, true) == gl_RayQueryCommittedIntersectionTriangleEXT)
    {
      // float t = rayQueryGetIntersectionTEXT(rq, true);
      // rayQueryGetIntersectionBarycentricsEXT
      // rayQueryGetIntersectionPrimitiveIndexEXT
      // rayQueryGetIntersectionGeometryIndexEXT
      // rayQueryGetIntersectionInstanceIdEXT
      // rayQueryGetIntersectionInstanceCustomIndexEXT
#if 1
      prepare_intersection(rq, w, x, n, st);
      vec3 ws = sample_cos(vec2(xrand(seed), xrand(seed)));
      vec3 du = normalize(cross(vec3(1, 2, 3), n));
      vec3 dv = normalize(cross(du, n));
      w = ws.x * du + ws.y * dv + ws.z * n;
      x += 0.001 * (n + w);
      rgb *= 0.2;
#else 
      x += t*w;
#endif
      // rgb = x;
      // rgb = (n + 1.0)/2.0;
      // break;
    }
    else break;
  }

  imageStore(img_out, ipos, vec4(rgb, 1));
}

